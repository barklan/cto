<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<filter docker.*.*>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    tag ${tag}
    stack_name ${tag_parts[1]}
    service_name ${tag_parts[2]}
    fluentd_hostname "#{ENV['FLUENTD_HOSTNAME']}"
    fluentd_time ${time}
  </record>
</filter>

<filter **>
  @type parser
  @log_level debug
  key_name log
  reserve_data true
  remove_key_name_field true
  emit_invalid_record_to_error false
  <parse>
    @type json
  </parse>
</filter>

<match docker.*.*>
  @type copy
  # <store>
  #   @type elasticsearch
  #   host elasticsearch
  #   port 9200
  #   logstash_format true
  #   logstash_prefix fluentd
  #   logstash_dateformat %Y.%m.%d
  #   include_tag_key true
  #   type_name access_log
  #   tag_key @log_name
  #   <buffer>
  #     flush_interval 1s
  #     flush_thread_count 2
  #   </buffer>
  # </store>
  # <store>
  #   @type stdout
  # </store>
  <store>
    @type http

    endpoint "#{ENV['FLUENTD_HTTP_DUMP_ENDPOINT']}"
    open_timeout 2
    retryable_response_codes [400, 401, 404, 502, 503]

    <auth>
      method basic
      username "#{ENV['FLUENTD_CTO_PROJECT_NAME']}"
      password "#{ENV['FLUENTD_CTO_PROJECT_TOKEN']}"
    </auth>

    <format>
      @type json
    </format>
    json_array true
    <buffer>
      flush_interval 5s
      retry_type exponential_backoff
      retry_max_interval 50s
      disable_chunk_backup true
    </buffer>
  </store>
</match>
